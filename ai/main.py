# %%
import os
import torch
import torch.nn as nn
import matplotlib.pyplot as plt
# %%
import kagglehub

data_path = kagglehub.dataset_download("khyeh0719/ptb-xl-dataset")

print("Path to dataset files:", data_path)
# %%
import pandas as pd
import numpy as np
import wfdb
import ast

def load_raw_data(df, sampling_rate, path):
    if sampling_rate == 100:
        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]
    else:
        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]
    data = np.array([signal for signal, meta in data])
    return data

path = data_path + '/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.1/'
sampling_rate=100

# load and convert annotation data
Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')
Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))


# Load raw signal data
X = load_raw_data(Y, sampling_rate, path)

# %%
X = X[:,:,:6]
X.shape

# %%
X
# %%

# Load scp_statements.csv for diagnostic aggregation
agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)
agg_df = agg_df[agg_df.diagnostic == 1]
print(agg_df.shape)
agg_df.head()
# %%

def aggregate_diagnostic(y_dic):
    tmp = []
    for key in y_dic.keys():
        if key in agg_df.index:
            tmp.append(agg_df.loc[key].diagnostic_class)
    return list(set(tmp))

# Apply diagnostic superclass
Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)

# %%
def safe_literal_eval(val):
    if isinstance(val, str):
        try:
            return ast.literal_eval(val)
        except (ValueError, SyntaxError):
            return []  # –∏–ª–∏ –≤–µ—Ä–Ω–∏ val, –µ—Å–ª–∏ —Ö–æ—á–µ—à—å –æ—Å—Ç–∞–≤–∏—Ç—å –∫–∞–∫ –µ—Å—Ç—å
    elif isinstance(val, list):
        return val  # —É–∂–µ —Å–ø–∏—Å–æ–∫ ‚Äî –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞–µ–º
    else:
        return []  # –Ω–∞ —Å–ª—É—á–∞–π NaN –∏–ª–∏ None

# –ü—Ä–∏–º–µ–Ω—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
Y['diagnostic_superclass'] = Y['diagnostic_superclass'].apply(safe_literal_eval)

# –¢–µ–ø–µ—Ä—å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è
allowed_classes = {'NORM', 'CD', 'ARRHYTHMIA'}
Y = Y[Y['diagnostic_superclass'].apply(
    lambda diag_list: isinstance(diag_list, list) and all(d in allowed_classes for d in diag_list)
)].reset_index(drop=True)

print(f"–û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π: {len(Y)}")

# %%
# print(Y.scp_codes)

def aggregate_subclass_diagnostic(y_dic):
    allowed_superclasses = {'NORM', 'CD', 'ARRHYTHMIA'}
    tmp = []
    for key in y_dic.keys():
        if key in agg_df.index:
            supercls = agg_df.loc[key]['diagnostic_class']
            if supercls in allowed_superclasses:
                tmp.append(agg_df.loc[key]['diagnostic_subclass'])
    ret = list(set(tmp))  # —É–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    ret = ['sub_' + r for r in ret]  # –ø—Ä–µ—Ñ–∏–∫—Å –¥–ª—è –æ—Ç–ª–∏—á–∏—è –æ—Ç —Å—É–ø–µ—Ä–∫–ª–∞—Å—Å–æ–≤
    return ret
# Apply diagnostic subclass
Y['diagnostic_subclass'] = Y.scp_codes.apply(aggregate_subclass_diagnostic)

# %%
import missingno as msno

msno.matrix(Y)
plt.show()

# %%

# –ó–∞–ø–æ–ª–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —á–∏—Å–ª–æ–≤—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–∞—Ö
Y['age'].fillna(0, inplace=True)
Y['sex'].fillna(0, inplace=True)
Y['height'].fillna(0, inplace=True)
Y['weight'].fillna(0, inplace=True)

# –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –∞–Ω–æ–º–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π —Ä–æ—Å—Ç–∞ (< 50 —Å–º ‚Äî —è–≤–Ω–æ –æ—à–∏–±–∫–∞)
Y.loc[Y['height'] < 50, 'height'] = np.nan
Y['height'].fillna(0, inplace=True)

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–¥–∏–∏ –∏–Ω—Ñ–∞—Ä–∫—Ç–∞ 1
Y['infarction_stadium1'] = Y['infarction_stadium1'].replace({
    'unknown': 0,
    'Stadium I': 1,
    'Stadium I-II': 2,
    'Stadium II': 3,
    'Stadium II-III': 4,
    'Stadium III': 5
}).fillna(0).astype(int)

# –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç–∞–¥–∏–∏ –∏–Ω—Ñ–∞—Ä–∫—Ç–∞ 2
Y['infarction_stadium2'] = Y['infarction_stadium2'].replace({
    'unknown': 0,
    'Stadium I': 1,
    'Stadium II': 2,
    'Stadium III': 3
}).fillna(0).astype(int)

# –ë–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –Ω–∞–ª–∏—á–∏—è –∫–∞—Ä–¥–∏–æ—Å—Ç–∏–º—É–ª—è—Ç–æ—Ä–∞
Y['pacemaker'] = (Y['pacemaker'] == 'ja, pacemaker').astype(float)

# %%
# –°—Ç–æ–ª–±—Ü—ã, –∫–æ—Ç–æ—Ä—ã–µ –ù–ï –Ω—É–∂–Ω—ã –¥–ª—è —Ç–≤–æ–µ–π –∑–∞–¥–∞—á–∏
columns_to_drop = [
    'infarction_stadium1',
    'infarction_stadium2',
    'nurse',
    'site',
    'device',
    'recording_date',
    'report',
    'validated_by',
    'second_opinion',
    'initial_autogenerated_report',
    'validated_by_human',
    'baseline_drift',
    'static_noise',
    'burst_noise',
    'electrodes_problems',
    'extra_beats'
]

# –£–¥–∞–ª—è–µ–º –∏—Ö (–µ—Å–ª–∏ –µ—Å—Ç—å)
Y = Y.drop(columns=[col for col in columns_to_drop if col in Y.columns])

# –ü—Ä–æ–≤–µ—Ä–∫–∞
print("–û—Å—Ç–∞–ª–æ—Å—å —Å—Ç–æ–ª–±—Ü–æ–≤:", len(Y.columns))
print(Y.columns.tolist())

# %%
# === –ü–†–ï–î–û–ë–†–ê–ë–û–¢–ö–ê –°–ò–ì–ù–ê–õ–û–í: –§–ò–õ–¨–¢–†–ê–¶–ò–Ø + –°–¢–ê–ù–î–ê–†–¢–ò–ó–ê–¶–ò–Ø ===
from scipy import signal

def preprocess_ecg_batch(X, fs=100):
    # Bandpass 0.5‚Äì40 Hz
    sos = signal.butter(4, [0.5, 40], btype='band', fs=fs, output='sos')
    X = signal.sosfilt(sos, X, axis=1)
    # Z-score –ø–æ –∫–∞–∂–¥–æ–º—É –æ—Ç–≤–µ–¥–µ–Ω–∏—é
    X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-6)
    return X

print("–ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ —Å–∏–≥–Ω–∞–ª–æ–≤...")
X = preprocess_ecg_batch(X, fs=sampling_rate)
print("‚úÖ –°–∏–≥–Ω–∞–ª—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω—ã –∏ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∏–∑–∏—Ä–æ–≤–∞–Ω—ã.")
# %%
original_index = Y.index.copy()

X = X[original_index]

# %%
# –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫–æ–Ω—Ç–µ–π–Ω–µ—Ä–æ–≤ –¥–ª—è —Å–±–æ—Ä–∞ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π –∏ –∑–Ω–∞—á–µ–Ω–∏–π
all_keys = set()
all_values = set()

# –ü—Ä–æ—Ö–æ–¥–∏–º –ø–æ –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–µ (–∫–∞–∂–¥–æ–º—É –æ–±—ä–µ–∫—Ç—É)
for row in Y['scp_codes']:
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∫–ª—é—á–∏ –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞
    all_keys.update(row.keys())
    
    # –î–æ–±–∞–≤–ª—è–µ–º –≤—Å–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ —Ç–µ–∫—É—â–µ–≥–æ –æ–±—ä–µ–∫—Ç–∞
    all_values.update(row.values())

# –ü–µ—á–∞—Ç—å —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∫–ª—é—á–µ–π –∏ –∑–Ω–∞—á–µ–Ω–∏–π
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏:", *sorted(all_keys))
print("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è:", *sorted(all_values))

# %%
valid_scp_codes = {
    # –†–∏—Ç–º—ã
    'SR', 'AFIB', 'AFLT', 'PAC', 'PVC', 'SVTAC', 'SARRH', 'SBRAD', 'STACH',
    # –ë–ª–æ–∫–∞–¥—ã –∏ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ø—Ä–æ–≤–æ–¥–∏–º–æ—Å—Ç–∏
    '1AVB', '2AVB', '3AVB', 
    'CRBBB', 'CLBBB', 'IRBBB', 'ILBBB',
    'LAFB', 'LPFB',
    # –°–∏–Ω–¥—Ä–æ–º—ã –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
    'WPW', 'BIGU', 'TRIGU',
    # –ù–æ—Ä–º–∞
    'NORM'
}

# === –®–ê–ì 2: –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –∑–∞–ø–∏—Å–µ–π ===
# –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ, —É –∫–æ—Ç–æ—Ä—ã—Ö –í–°–ï –∫–æ–¥—ã ‚àà valid_scp_codes
def is_valid_record(scp_dict):
    return all(code in valid_scp_codes for code in scp_dict.keys())

mask_valid = Y['scp_codes'].apply(is_valid_record)
Y = Y[mask_valid].reset_index(drop=True)

print(f"‚úÖ –û—Å—Ç–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–µ–π –ø–æ—Å–ª–µ —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏: {len(Y)}")

# %%
# === –®–ê–ì 3: –í—ã–±–∏—Ä–∞–µ–º –¢–û–õ–¨–ö–û —Ç–µ –¥–∏–∞–≥–Ω–æ–∑—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—É–¥–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑—ã–≤–∞—Ç—å –ò–ò ===
# (–∏—Å–∫–ª—é—á–∞–µ–º SBRAD/STACH ‚Äî –æ–Ω–∏ –≤—ã–≤–æ–¥—è—Ç—Å—è –∏–∑ SR + –ß–°–°)
ii_targets = {
    'is_sinus_rhythm': 'SR',
    'is_afib': 'AFIB',
    'is_aflt': 'AFLT',
    'is_pac': 'PAC',
    'is_pvc': 'PVC',
    'is_svt': 'SVTAC',
    'is_sinus_arrhythmia': 'SARRH',
    'has_1avb': '1AVB',
    'has_2avb': '2AVB',
    'has_3avb': '3AVB',
    'has_rbbb': 'CRBBB',      # complete RBBB
    'has_lbbb': 'CLBBB',      # complete LBBB
    'has_irbbb': 'IRBBB',     # incomplete RBBB
    'has_ilbbb': 'ILBBB',     # incomplete LBBB
    'has_lafb': 'LAFB',
    'has_lpfb': 'LPFB',
    'has_wpw': 'WPW',
    'has_bigeminy': 'BIGU',
    'has_trigeminy': 'TRIGU'
}

# –°–æ–∑–¥–∞—ë–º –±–∏–Ω–∞—Ä–Ω—ã–µ –º–µ—Ç–∫–∏
for col_name, scp_code in ii_targets.items():
    Y[col_name] = Y['scp_codes'].apply(lambda x: 1 if scp_code in x else 0)

target_cols = list(ii_targets.keys())
print(f"üéØ –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ò–ò ({len(target_cols)} —à—Ç.):")
print(target_cols)

# %%

# === –®–ê–ì 4: –û—Ç—Ñ–∏–ª—å—Ç—Ä—É–π X –ø–æ —Ç–µ–º –∂–µ –∏–Ω–¥–µ–∫—Å–∞–º, —á—Ç–æ –∏ Y ===
# (–¥–µ–ª–∞–π —ç—Ç–æ –ü–û–°–õ–ï —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏ Y, –Ω–æ –î–û –∑–∞–≥—Ä—É–∑–∫–∏ X, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ)
# –ï—Å–ª–∏ X —É–∂–µ –∑–∞–≥—Ä—É–∂–µ–Ω –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ Y ‚Äî —Å–¥–µ–ª–∞–π —Ç–∞–∫:
X = X[Y.index]  # ‚Üê –≠–¢–û –û–ë–Ø–ó–ê–¢–ï–õ–¨–ù–û!

# === –®–ê–ì 5: –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/test —Å –ø–æ–º–æ—â—å—é strat_fold ===
test_fold = 10
test_mask = (Y['strat_fold'] == test_fold)
train_mask = ~test_mask

# –°–∏–≥–Ω–∞–ª—ã (—É–∂–µ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ: —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏—è + –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è)
X_train = X[train_mask]  # shape: (N_train, 1000, 6)
X_test = X[test_mask]    # shape: (N_test, 1000, 6)

# –¶–µ–ª–µ–≤—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –¥–ª—è –ò–ò (–º—É–ª—å—Ç–∏–ª–µ–π–±–ª)
y_train = Y.loc[train_mask, target_cols].values.astype(np.float32)  # shape: (N_train, num_targets)
y_test = Y.loc[test_mask, target_cols].values.astype(np.float32)    # shape: (N_test, num_targets)

print(f"\n‚úÖ –ì–æ—Ç–æ–≤–æ!")
print(f"X_train: {X_train.shape}, y_train: {y_train.shape}")
print(f"X_test:  {X_test.shape},  y_test:  {y_test.shape}")

# === –®–ê–ì 6: –ü—Ä–æ–≤–µ—Ä–∫–∞ –±–∞–ª–∞–Ω—Å–∞ (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) ===
print("\nüìä –ë–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ –≤ train:")
for i, col in enumerate(target_cols):
    pos = y_train[:, i].sum()
    total = len(y_train)
    print(f"{col}: {int(pos)} / {total} ({pos/total:.1%})")
# %%
# Split data into train and test
# test_fold = 10
# # Train
# X_train = X[np.where(Y.strat_fold != test_fold)]
# y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass
# # Test
# X_test = X[np.where(Y.strat_fold == test_fold)]
# y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass

# %%
import os
import numpy as np
import pandas as pd

# –°–æ–∑–¥–∞—ë–º –ø–∞–ø–∫—É –¥–ª—è –¥–∞–Ω–Ω—ã—Ö (–µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç)
output_dir = 'ecg_data'
os.makedirs(output_dir, exist_ok=True)

# === 1. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–∏–≥–Ω–∞–ª—ã –∏ –º—É–ª—å—Ç–∏–ª–µ–π–±–ª-–º–µ—Ç–∫–∏ –ò–ò ===
np.save(os.path.join(output_dir, 'X_train.npy'), X_train)
np.save(os.path.join(output_dir, 'X_test.npy'), X_test)
np.save(os.path.join(output_dir, 'y_train.npy'), y_train)
np.save(os.path.join(output_dir, 'y_test.npy'), y_test)

# === 2. –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ (–¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∏ –æ—Ç–ª–∞–¥–∫–∏) ===
Y_train_meta = Y[train_mask].copy()
Y_test_meta = Y[test_mask].copy()

Y_train_meta.to_csv(os.path.join(output_dir, 'Y_train.csv'), index=True)
Y_test_meta.to_csv(os.path.join(output_dir, 'Y_test.csv'), index=True)

# === 3. –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫ —Ü–µ–ª–µ–≤—ã—Ö –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö (—á—Ç–æ–±—ã –Ω–µ –∑–∞–±—ã—Ç—å –ø–æ—Ä—è–¥–æ–∫) ===
with open(os.path.join(output_dir, 'target_columns.txt'), 'w') as f:
    for col in target_cols:
        f.write(col + '\n')

print(f"‚úÖ –í—Å–µ –¥–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –ø–∞–ø–∫—É: '{output_dir}'")
print(f"   - –°–∏–≥–Ω–∞–ª—ã: X_train.npy, X_test.npy")
print(f"   - –ú–µ—Ç–∫–∏ –ò–ò: y_train.npy, y_test.npy")
print(f"   - –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ: Y_train.csv, Y_test.csv")
print(f"   - –¶–µ–ª–µ–≤—ã–µ —Å—Ç–æ–ª–±—Ü—ã: target_columns.txt")

# %%
